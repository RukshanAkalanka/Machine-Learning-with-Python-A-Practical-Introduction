{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.854</td>\n",
       "      <td>3.199</td>\n",
       "      <td>4.419</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.792</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.168</td>\n",
       "      <td>3.850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.163</td>\n",
       "      <td>3.866</td>\n",
       "      <td>3.219</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.824</td>\n",
       "      <td>3.240</td>\n",
       "      <td>5.247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0      11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1      33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2      23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3      38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4       7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "..      ...   ...      ...     ...  ...     ...    ...       ...       ...   \n",
       "195    55.0  44.0     24.0    83.0  1.0    23.0    0.0       1.0       0.0   \n",
       "196    34.0  23.0      3.0    24.0  1.0     7.0    0.0       1.0       0.0   \n",
       "197     6.0  32.0     10.0    47.0  1.0    10.0    0.0       1.0       0.0   \n",
       "198    24.0  30.0      0.0    25.0  4.0     5.0    0.0       1.0       1.0   \n",
       "199    61.0  50.0     16.0   190.0  2.0    22.0    1.0       1.0       1.0   \n",
       "\n",
       "     longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0       4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1       9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2       6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3       6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4       7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "..       ...  ...    ...       ...       ...     ...    ...      ...      ...   \n",
       "195    17.35  ...    0.0       0.0       0.0     1.0    0.0    2.854    3.199   \n",
       "196     6.00  ...    0.0       0.0       1.0     1.0    0.0    1.792    3.332   \n",
       "197     3.85  ...    0.0       0.0       1.0     1.0    0.0    1.348    3.168   \n",
       "198     8.70  ...    1.0       1.0       1.0     1.0    1.0    2.163    3.866   \n",
       "199    16.85  ...    0.0       1.0       0.0     0.0    1.0    2.824    3.240   \n",
       "\n",
       "     lninc  custcat  churn  \n",
       "0    4.913      4.0    1.0  \n",
       "1    3.497      1.0    1.0  \n",
       "2    3.401      3.0    0.0  \n",
       "3    4.331      4.0    0.0  \n",
       "4    4.382      3.0    0.0  \n",
       "..     ...      ...    ...  \n",
       "195  4.419      3.0    0.0  \n",
       "196  3.178      3.0    0.0  \n",
       "197  3.850      3.0    0.0  \n",
       "198  3.219      4.0    1.0  \n",
       "199  5.247      2.0    0.0  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df= pd.read_csv('ChurnData.csv')\n",
    "churn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure      float64\n",
       "age         float64\n",
       "address     float64\n",
       "income      float64\n",
       "ed          float64\n",
       "employ      float64\n",
       "equip       float64\n",
       "callcard    float64\n",
       "wireless    float64\n",
       "churn         int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df= churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "churn_df['churn']= churn_df['churn'].astype('int')\n",
    "churn_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142\n",
       "1     58\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10)\n",
      "Index(['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',\n",
      "       'callcard', 'wireless', 'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(churn_df.shape)\n",
    "print(churn_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 33.,  7., ...,  0.,  1.,  1.],\n",
       "       [33., 33., 12., ...,  0.,  0.,  0.],\n",
       "       [23., 30.,  9., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 6., 32., 10., ...,  0.,  1.,  0.],\n",
       "       [24., 30.,  0., ...,  0.,  1.,  1.],\n",
       "       [61., 50., 16., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless']])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= np.asarray(churn_df['churn'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 , ..., -0.85972695,\n",
       "         0.64686916,  1.56469673],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, ..., -0.85972695,\n",
       "        -1.54590766, -0.63910148],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , ..., -0.85972695,\n",
       "        -1.54590766, -0.63910148],\n",
       "       ...,\n",
       "       [-1.36680743, -0.7026181 , -0.16283445, ..., -0.85972695,\n",
       "         0.64686916, -0.63910148],\n",
       "       [-0.53296457, -0.85594447, -1.14970993, ..., -0.85972695,\n",
       "         0.64686916,  1.56469673],\n",
       "       [ 1.18104577,  0.67731925,  0.42929083, ...,  1.16316   ,\n",
       "         0.64686916,  1.56469673]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "x= preprocessing.StandardScaler().fit(x).transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  (160, 9) (160,)\n",
      "test set:  (40, 9) (40,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "print('train set: ',x_train.shape, y_train.shape)\n",
    "print('test set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR= LogisticRegression(C=0.01, solver='liblinear').fit(x_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat= LR.predict(x_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58711718, 0.41288282],\n",
       "       [0.56650898, 0.43349102],\n",
       "       [0.5313329 , 0.4686671 ],\n",
       "       [0.66722528, 0.33277472],\n",
       "       [0.53481231, 0.46518769],\n",
       "       [0.59508358, 0.40491642],\n",
       "       [0.49995014, 0.50004986],\n",
       "       [0.56532893, 0.43467107],\n",
       "       [0.39939231, 0.60060769],\n",
       "       [0.59368426, 0.40631574],\n",
       "       [0.54844546, 0.45155454],\n",
       "       [0.58957413, 0.41042587],\n",
       "       [0.52439771, 0.47560229],\n",
       "       [0.41344893, 0.58655107],\n",
       "       [0.68930146, 0.31069854],\n",
       "       [0.51576247, 0.48423753],\n",
       "       [0.4969602 , 0.5030398 ],\n",
       "       [0.46038301, 0.53961699],\n",
       "       [0.47010467, 0.52989533],\n",
       "       [0.57170621, 0.42829379],\n",
       "       [0.50781873, 0.49218127],\n",
       "       [0.49802608, 0.50197392],\n",
       "       [0.66938224, 0.33061776],\n",
       "       [0.49625351, 0.50374649],\n",
       "       [0.47635919, 0.52364081],\n",
       "       [0.73040145, 0.26959855],\n",
       "       [0.45111513, 0.54888487],\n",
       "       [0.49187403, 0.50812597],\n",
       "       [0.4927476 , 0.5072524 ],\n",
       "       [0.73618723, 0.26381277],\n",
       "       [0.70809718, 0.29190282],\n",
       "       [0.5549927 , 0.4450073 ],\n",
       "       [0.40681176, 0.59318824],\n",
       "       [0.73720605, 0.26279395],\n",
       "       [0.6355682 , 0.3644318 ],\n",
       "       [0.60354024, 0.39645976],\n",
       "       [0.45884949, 0.54115051],\n",
       "       [0.56829807, 0.43170193],\n",
       "       [0.68914305, 0.31085695],\n",
       "       [0.48020907, 0.51979093]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob= LR.predict_proba(x_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D.R.A KUMARAGE\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:635: DeprecationWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  'and multiclass classification tasks.', DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  7]\n",
      " [ 7 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title= 'confusion_matrix', cmap= plt.cm.Blues):\n",
    "    \n",
    "    if normalize:\n",
    "        cm= cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalize Confusion Matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, Without Normalize')\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation= 'nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks= np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation= 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt= '.2f' if normalize else 'd'\n",
    "    thresh= cm.max()/2.\n",
    "    \n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True lable')\n",
    "    plt.xlabel('predicted lable')\n",
    "    \n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, Without Normalize\n",
      "[[ 8  7]\n",
      " [ 7 18]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix= confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'], normalize=False, title='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72        25\n",
      "           1       0.53      0.53      0.53        15\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.63      0.63      0.63        40\n",
      "weighted avg       0.65      0.65      0.65        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6155809757244557"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test,yhat_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.62\n"
     ]
    }
   ],
   "source": [
    "LR2= LogisticRegression(C=0.01, solver='sag').fit(x_train,y_train)\n",
    "yhat_prob_2= LR2.predict_proba(x_test)\n",
    "print(\"Log loss: %.2f\" % log_loss(y_test,yhat_prob_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
